{
  "__inputs": [
    {
      "name": "DS_PROMETHEUS",
      "label": "Prometheus",
      "description": "InferFlux Prometheus data source",
      "type": "datasource",
      "pluginId": "prometheus",
      "pluginName": "Prometheus"
    }
  ],
  "__requires": [
    { "type": "grafana", "id": "grafana", "name": "Grafana", "version": "10.0.0" },
    { "type": "datasource", "id": "prometheus", "name": "Prometheus", "version": "1.0.0" },
    { "type": "panel", "id": "timeseries", "name": "Time series", "version": "" },
    { "type": "panel", "id": "gauge", "name": "Gauge", "version": "" },
    { "type": "panel", "id": "stat", "name": "Stat", "version": "" }
  ],
  "annotations": { "list": [] },
  "description": "InferFlux inference server — request throughput, latency, queue depth, token production, cache efficiency, and GGML kernel timings.",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [],
  "panels": [
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 0 },
      "id": 100,
      "title": "Overview",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": { "lineWidth": 2 },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": { "h": 7, "w": 8, "x": 0, "y": 1 },
      "id": 1,
      "options": { "tooltip": { "mode": "multi" } },
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_requests_total[1m])",
          "legendFormat": "requests/s — {{backend}}",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_errors_total[1m])",
          "legendFormat": "errors/s — {{backend}}",
          "refId": "B"
        }
      ],
      "title": "Request Rate",
      "type": "timeseries"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": { "lineWidth": 2 },
          "unit": "ms"
        },
        "overrides": []
      },
      "gridPos": { "h": 7, "w": 8, "x": 8, "y": 1 },
      "id": 2,
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "histogram_quantile(0.50, rate(inferflux_request_duration_ms_bucket[1m]))",
          "legendFormat": "p50 — {{backend}}",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "histogram_quantile(0.95, rate(inferflux_request_duration_ms_bucket[1m]))",
          "legendFormat": "p95 — {{backend}}",
          "refId": "B"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "histogram_quantile(0.99, rate(inferflux_request_duration_ms_bucket[1m]))",
          "legendFormat": "p99 — {{backend}}",
          "refId": "C"
        }
      ],
      "title": "End-to-End Request Latency",
      "type": "timeseries"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 10 },
              { "color": "red", "value": 20 }
            ]
          },
          "unit": "short",
          "min": 0,
          "max": 50
        },
        "overrides": []
      },
      "gridPos": { "h": 7, "w": 8, "x": 16, "y": 1 },
      "id": 3,
      "options": { "reduceOptions": { "calcs": ["lastNotNull"] }, "orientation": "auto", "textMode": "auto" },
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "inferflux_scheduler_queue_depth",
          "legendFormat": "Queue depth",
          "refId": "A"
        }
      ],
      "title": "Scheduler Queue Depth",
      "type": "gauge"
    },
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 8 },
      "id": 101,
      "title": "Token Throughput",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": { "lineWidth": 2 },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": { "h": 7, "w": 12, "x": 0, "y": 9 },
      "id": 4,
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_llama_generated_tokens_total[1m])",
          "legendFormat": "generated tok/s — {{backend}}",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_llama_prompt_tokens_total[1m])",
          "legendFormat": "prompt tok/s — {{backend}}",
          "refId": "B"
        }
      ],
      "title": "Token Throughput (GGML-native)",
      "type": "timeseries"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": { "lineWidth": 2 },
          "unit": "percentunit",
          "min": 0,
          "max": 1
        },
        "overrides": []
      },
      "gridPos": { "h": 7, "w": 12, "x": 12, "y": 9 },
      "id": 5,
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_prefix_hits_total[1m]) / clamp_min(rate(inferflux_prefix_hits_total[1m]) + rate(inferflux_prefix_misses_total[1m]), 0.001)",
          "legendFormat": "RadixCache hit rate — {{backend}}",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_kv_prefix_reuse_total[1m]) / clamp_min(rate(inferflux_requests_total[1m]), 0.001)",
          "legendFormat": "KV warm prefix reuse rate",
          "refId": "B"
        }
      ],
      "title": "Prefix Cache Hit Rate",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 16 },
      "id": 102,
      "title": "GGML Kernel Latency",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": { "lineWidth": 2 },
          "unit": "ms"
        },
        "overrides": []
      },
      "gridPos": { "h": 7, "w": 12, "x": 0, "y": 17 },
      "id": 6,
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "histogram_quantile(0.50, rate(inferflux_llama_prefill_ms_bucket[1m]))",
          "legendFormat": "prefill p50 — {{backend}}",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "histogram_quantile(0.95, rate(inferflux_llama_prefill_ms_bucket[1m]))",
          "legendFormat": "prefill p95 — {{backend}}",
          "refId": "B"
        }
      ],
      "title": "GGML Prefill Latency",
      "type": "timeseries"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": { "lineWidth": 2 },
          "unit": "ms"
        },
        "overrides": []
      },
      "gridPos": { "h": 7, "w": 12, "x": 12, "y": 17 },
      "id": 7,
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "histogram_quantile(0.50, rate(inferflux_llama_decode_ms_bucket[1m]))",
          "legendFormat": "decode p50 — {{backend}}",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "histogram_quantile(0.95, rate(inferflux_llama_decode_ms_bucket[1m]))",
          "legendFormat": "decode p95 — {{backend}}",
          "refId": "B"
        }
      ],
      "title": "GGML Decode Latency (per-token)",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 24 },
      "id": 103,
      "title": "Fairness & Speculative Decoding",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": { "lineWidth": 2 },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": { "h": 7, "w": 12, "x": 0, "y": 25 },
      "id": 8,
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_fairness_yields_total[1m])",
          "legendFormat": "yields/s — {{backend}}",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_fairness_preemptions_total[1m])",
          "legendFormat": "preemptions/s — {{backend}}",
          "refId": "B"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_fairness_resumes_total[1m])",
          "legendFormat": "resumes/s — {{backend}}",
          "refId": "C"
        }
      ],
      "title": "Fairness Scheduler Activity",
      "type": "timeseries"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": { "lineWidth": 2 },
          "unit": "percentunit",
          "min": 0,
          "max": 1
        },
        "overrides": []
      },
      "gridPos": { "h": 7, "w": 12, "x": 12, "y": 25 },
      "id": 9,
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${DS_PROMETHEUS}" },
          "expr": "rate(inferflux_spec_chunks_accepted_total[1m]) / clamp_min(rate(inferflux_spec_chunks_total[1m]), 0.001)",
          "legendFormat": "speculative accept rate — {{backend}}",
          "refId": "A"
        }
      ],
      "title": "Speculative Decoding Accept Rate",
      "type": "timeseries"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "tags": ["inferflux", "llm", "inference"],
  "templating": {
    "list": [
      {
        "current": {},
        "hide": 0,
        "includeAll": false,
        "label": "Data source",
        "multi": false,
        "name": "DS_PROMETHEUS",
        "options": [],
        "query": "prometheus",
        "refresh": 1,
        "type": "datasource"
      }
    ]
  },
  "time": { "from": "now-1h", "to": "now" },
  "timepicker": {},
  "timezone": "browser",
  "title": "InferFlux",
  "uid": "inferflux-main",
  "version": 1
}
